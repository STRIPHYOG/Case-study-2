{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2l04GYmYu-F-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, LeakyReLU\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "211-HCcrvKaL",
        "outputId": "4dbac96d-1c79-40b0-e58b-925f08eb70d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "vnsfoAiNvKX3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "6M2EzqiJvKVY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Relu\n",
        "def build_relu_model():\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "T2wjKenivKS7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leaky Relu\n",
        "def build_leakyrelu_model():\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(128),\n",
        "        LeakyReLU(alpha=0.01),\n",
        "        Dense(64),\n",
        "        LeakyReLU(alpha=0.01),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "jaoDJUZuvKQy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Relu\n",
        "\n",
        "metrics_results = {}\n",
        "\n",
        "relu_model = build_relu_model()\n",
        "history_relu = relu_model.fit(x_train, y_train_cat, epochs=5, batch_size=128,\n",
        "                              validation_split=0.1, verbose=1)\n",
        "\n",
        "# Predictions\n",
        "y_pred_relu = np.argmax(relu_model.predict(x_test), axis=1)\n",
        "\n",
        "# Compute metrics\n",
        "relu_metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_relu),\n",
        "    \"Error Rate\": 1 - accuracy_score(y_test, y_pred_relu),\n",
        "    \"Precision\": precision_score(y_test, y_pred_relu, average='macro'),\n",
        "    \"Recall\": recall_score(y_test, y_pred_relu, average='macro'),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_relu, average='macro')\n",
        "}\n",
        "metrics_results['ReLU'] = relu_metrics\n",
        "\n",
        "print(\"\\nClassification Report (ReLU):\")\n",
        "print(classification_report(y_test, y_pred_relu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYLvEYd8vKOK",
        "outputId": "90946c57-50b7-4350-b67a-64128e3f234f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8238 - loss: 0.6303 - val_accuracy: 0.9625 - val_loss: 0.1381\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.1495 - val_accuracy: 0.9693 - val_loss: 0.1055\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9681 - loss: 0.1050 - val_accuracy: 0.9753 - val_loss: 0.0858\n",
            "Epoch 4/5\n",
            "\u001b[1m255/422\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0725"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Leaky Relu\n",
        "\n",
        "leakyrelu_model = build_leakyrelu_model()\n",
        "history_leaky = leakyrelu_model.fit(x_train, y_train_cat, epochs=5, batch_size=128,\n",
        "validation_split=0.1, verbose=1)\n",
        "\n",
        "# Predictions\n",
        "y_pred_leaky = np.argmax(leakyrelu_model.predict(x_test), axis=1)\n",
        "\n",
        "# Compute metrics\n",
        "leaky_metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_leaky),\n",
        "    \"Error Rate\": 1 - accuracy_score(y_test, y_pred_leaky),\n",
        "    \"Precision\": precision_score(y_test, y_pred_leaky, average='macro'),\n",
        "    \"Recall\": recall_score(y_test, y_pred_leaky, average='macro'),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_leaky, average='macro')\n",
        "}\n",
        "metrics_results['Leaky ReLU'] = leaky_metrics\n",
        "\n",
        "print(\"\\nClassification Report (Leaky ReLU):\")\n",
        "print(classification_report(y_test, y_pred_leaky))"
      ],
      "metadata": {
        "id": "u3TMSed6vKL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history_relu.history['accuracy'], label='ReLU Train Accuracy')\n",
        "plt.plot(history_relu.history['val_accuracy'], label='ReLU Val Accuracy')\n",
        "plt.plot(history_leaky.history['accuracy'], label='Leaky ReLU Train Accuracy')\n",
        "plt.plot(history_leaky.history['val_accuracy'], label='Leaky ReLU Val Accuracy')\n",
        "plt.title(\"Training and Validation Accuracy over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vyr9P48VvKI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'Activation':<12}{'Accuracy':>12}{'Error Rate':>15}{'Precision':>15}{'Recall':>12}{'F1 Score':>12}\")\n",
        "print(\"-\"*78)\n",
        "for act, metrics in metrics_results.items():\n",
        "    print(f\"{act:<12}\"\n",
        "          f\"{metrics['Accuracy']*100:>11.2f}%\"\n",
        "          f\"{metrics['Error Rate']*100:>14.2f}%\"\n",
        "          f\"{metrics['Precision']*100:>14.2f}%\"\n",
        "          f\"{metrics['Recall']*100:>11.2f}%\"\n",
        "          f\"{metrics['F1 Score']*100:>11.2f}%\")\n"
      ],
      "metadata": {
        "id": "7xbzKD8LvKBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Error Rate\"]\n",
        "relu_values = [\n",
        "    metrics_results[\"ReLU\"][\"Accuracy\"] * 100,\n",
        "    metrics_results[\"ReLU\"][\"Precision\"] * 100,\n",
        "    metrics_results[\"ReLU\"][\"Recall\"] * 100,\n",
        "    metrics_results[\"ReLU\"][\"F1 Score\"] * 100,\n",
        "    metrics_results[\"ReLU\"][\"Error Rate\"] * 100,\n",
        "]\n",
        "leaky_values = [\n",
        "    metrics_results[\"Leaky ReLU\"][\"Accuracy\"] * 100,\n",
        "    metrics_results[\"Leaky ReLU\"][\"Precision\"] * 100,\n",
        "    metrics_results[\"Leaky ReLU\"][\"Recall\"] * 100,\n",
        "    metrics_results[\"Leaky ReLU\"][\"F1 Score\"] * 100,\n",
        "    metrics_results[\"Leaky ReLU\"][\"Error Rate\"] * 100,\n",
        "]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars1 = plt.bar(x - width/2, relu_values, width, label=\"ReLU\", color=\"skyblue\", edgecolor='black')\n",
        "bars2 = plt.bar(x + width/2, leaky_values, width, label=\"Leaky ReLU\", color=\"orange\", edgecolor='black')\n",
        "\n",
        "\n",
        "plt.title(\"Performance Comparison: ReLU vs Leaky ReLU\", fontsize=14, weight='bold')\n",
        "plt.ylabel(\"Score (%)\", fontsize=12)\n",
        "plt.xticks(x, labels)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(\n",
        "            bar.get_x() + bar.get_width()/2,\n",
        "            yval + 0.2,\n",
        "            f\"{yval:.2f}%\",\n",
        "            ha='center',\n",
        "            va='bottom',\n",
        "            fontsize=9,\n",
        "            weight='bold'\n",
        "        )\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "opRRhXPRzRnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "error_rate_values = [\n",
        "    metrics_results[\"ReLU\"][\"Error Rate\"] * 100,\n",
        "    metrics_results[\"Leaky ReLU\"][\"Error Rate\"] * 100,\n",
        "]\n",
        "\n",
        "plt.bar([\"ReLU\", \"Leaky ReLU\"], error_rate_values, color=['skyblue', 'orange'])\n",
        "plt.title(\"Error Rate Comparison between ReLU and Leaky ReLU\")\n",
        "plt.ylabel(\"Error Rate (%)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OgAGJB9GzRf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}